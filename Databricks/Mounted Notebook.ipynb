{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7554bbe6-023c-43d7-a477-ec0be17974cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configs = {\n",
    "    \"fs.azure.account.auth.type\": \"CustomAccessToken\",\n",
    "    \"fs.azure.account.custom.token.provider.class\":spark.conf.get(\"spark.databricks.passthrough.adls.gen2.tokenProviderClassName\")\n",
    "}\n",
    "\n",
    "# Optionally, you can add  to the source URI of your mount point.\n",
    "dbutils.fs.mount(\n",
    "    source = \"abfss://bronze@azureworkflowstorage.dfs.core.windows.net/\",\n",
    "    mount_point = \"/mnt/bronze\",\n",
    "    extra_configs = configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5a46170-f4b1-48a3-b823-6b6ab32064cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[FileInfo(path='dbfs:/mnt/bronze/Customer.csv', name='Customer.csv', size=150523, modificationTime=1745305026000),\n",
       " FileInfo(path='dbfs:/mnt/bronze/Inventory.csv', name='Inventory.csv', size=44806, modificationTime=1745305135000),\n",
       " FileInfo(path='dbfs:/mnt/bronze/Product.csv', name='Product.csv', size=27083, modificationTime=1745305149000),\n",
       " FileInfo(path='dbfs:/mnt/bronze/Sales.csv', name='Sales.csv', size=568435, modificationTime=1745305102000),\n",
       " FileInfo(path='dbfs:/mnt/bronze/Stores.csv', name='Stores.csv', size=8034, modificationTime=1745305118000)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbutils.fs.ls(\"/mnt/bronze\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7dfcd79f-fc7d-4ef6-bafa-c0d34881cba7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configs = {\n",
    "    \"fs.azure.account.auth.type\": \"CustomAccessToken\",\n",
    "    \"fs.azure.account.custom.token.provider.class\": spark.conf.get(\"spark.databricks.passthrough.adls.gen2.tokenProviderClassName\")}\n",
    "\n",
    "\n",
    "dbutils.fs.mount(\n",
    "    source = \"abfss://silver@azureworkflowstorage.dfs.core.windows.net/\",\n",
    "    mount_point = \"/mnt/silver\",\n",
    "    extra_configs = configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16394537-e42f-442e-ab95-52bac472b0bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbutils.fs.ls(\"/mnt/silver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7fa60546-f557-4839-83d6-e45e81e05373",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/gold has been unmounted.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbutils.fs.unmount(\"/mnt/gold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cab43fa9-49b1-4088-96c2-83063321903c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configs = {\n",
    "    \"fs.azure.account.auth.type\": \"CustomAccessToken\",\n",
    "    \"fs.azure.account.custom.token.provider.class\": spark.conf.get(\"spark.databricks.passthrough.adls.gen2.tokenProviderClassName\")}\n",
    "\n",
    "\n",
    "dbutils.fs.mount(\n",
    "    source = \"abfss://gold@azureworkflowstorage.dfs.core.windows.net/\",\n",
    "    mount_point = \"/mnt/gold\",\n",
    "    extra_configs = configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d923f765-e32a-414e-9a07-d4869ad5fd4b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Mount Azure Data Lake Storage to Databricks",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}